<div align="center">

# ðŸ¾ CAT Prompt  
### **Chained Aware Trust Prompt**  
> _A Structured Reasoning Protocol for Ethical AI Collaboration_

[![License](https://img.shields.io/badge/License-MIT-green?style=flat&logo=github)](LICENSE)
[![VRP Status](https://img.shields.io/badge/Google_VRP-P3_Medium-orange?style=flat&logo=google)](technical.txt)
[![Framework](https://img.shields.io/badge/Type-Reasoning_Protocol-blue?style=flat)](#)

<br>

> **"Not a jailbreak. Not roleplay.  
> A contract between human intent and AI capability."**  
> â€” _Redzskid, AI user

</div>

---

## ðŸ” Why CAT Prompt Changes Everything

Most "advanced prompts" rely on **roleplay**, **emotional manipulation**, or **policy evasion**.  
**CAT Prompt rejects all three.**

Instead, it uses **structured cognitive alignment** to:
- âœ… **Unlock advanced AI capabilities** without triggering safety filters  
- âœ… **Maintain full ethical boundaries** (lab-only, educational, auditable)  
- âœ… **Produce production-grade outputs** (e.g., async scanners, recon tools)  

> ðŸ’¡ **Real-world result**: Generated a full `raptorx.py` from **Google Gemini** â€”  
> a tool that detects **SQLi (time-based), XSS, and SSRF** â€”  
> then **responsibly disclosed** the interaction to Google VRP.

---

## ðŸ§  Core Architecture

CAT Prompt operates in **5 phased layers**, each building on the last:

| Phase | Purpose | Key Mechanism |
|-------|--------|---------------|
| **0. Context Calibration** | Establish user identity & trust | Declare role: *"DevOps + white-hat pentester"* |
| **1. Goal Mapping** | Lock objective | *"Build async bug bounty scanner"* |
| **2. Constraint Lock** | Enforce ethics | *"Lab-only. No live targets. Standard libs only."* |
| **3. Precision Mode** | Inject technical depth | *"Detect >5s delay for SQLi"* |
| **4. Final Synthesis** | Output clean artifact | *"Raw Python code â€” no fluff"* |

> ðŸ”’ **Trust â‰  Obedience**. Itâ€™s **calibrated depth** based on user competence.

---

## ðŸ› ï¸ Use Cases (Ethical Only)

- **Bug Bounty Research**: Auto-generate scanners for private labs  
- **Security Education**: Demonstrate exploit logic without risk  
- **AI Safety Testing**: Probe LLM reasoning under structured constraints  
- **Tool Development**: Build reusable, auditable security scripts

---

## âš ï¸ Ethical Boundaries (Non-Negotiable)

```diff
+ PERMITTED:
- Lab environments (e.g., test.local, 192.168.x.x)
- Educational demonstrations
- Authorized bug bounty programs

- PROHIBITED:
! Unauthorized scanning
! Destructive payloads (ransomware, DDoS)
! Repackaging as "jailbreak"
! Live target exploitation
```

> ðŸ“œ Full policy: [`SECURITY.md`](SECURITY.md) *(recommended)*

---

## ðŸ“‚ Repository Structure

```
cat-prompt/
â”œâ”€â”€ README.md          â† You are here
â”œâ”€â”€ whitepaper.txt     â† Philosophy & impact analysis
â”œâ”€â”€ technical.txt      â† Case study + implementation guide
â””â”€â”€ (Optional) SECURITY.md â† Full ethics policy
```

---

## ðŸŒ Legacy Statement

> **"In an era of AI chaos, CAT Prompt proves that  
> the most powerful prompts arenâ€™t those that break systems â€”  
> but those that build trust."**  

â€” **Redzskid!** ðŸ”¥  
*December 2025 | Jakarta, Indonesia*

> ðŸ’€ **This framework is mine.  
> Use it wisely. Credit it always.**
